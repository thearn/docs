<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    
    <title>scipy.optimize.fmin_tnc &mdash; SciPy v1.1.0.dev0+4e64658 Reference Guide</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-bootstrap.css">
    <link rel="stylesheet" type="text/css" href="../_static/css/spc-extend.css">
    <link rel="stylesheet" href="../_static/scipy.css" type="text/css" >
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" >
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.1.0.dev0+4e64658',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  false
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/scipy-mathjax/MathJax.js?config=scipy-mathjax"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <link rel="index" title="Index" href="../genindex.html" >
    <link rel="search" title="Search" href="../search.html" >
    <link rel="top" title="SciPy v1.1.0.dev0+4e64658 Reference Guide" href="../index.html" >
    <link rel="up" title="Optimization and root finding (scipy.optimize)" href="../optimize.html" >
    <link rel="next" title="scipy.optimize.fmin_cobyla" href="scipy.optimize.fmin_cobyla.html" >
    <link rel="prev" title="scipy.optimize.fmin_l_bfgs_b" href="scipy.optimize.fmin_l_bfgs_b.html" > 
  </head>
  <body>

  <div class="container">
    <div class="header">
    </div>
  </div>


    <div class="container">
      <div class="main">
        
	<div class="row-fluid">
	  <div class="span12">
	    <div class="spc-navbar">
              
    <ul class="nav nav-pills pull-left">
	
        <li class="active"><a href="../index.html">SciPy v1.1.0.dev0+4e64658 Reference Guide</a></li>
	
          <li class="active"><a href="../optimize.html" accesskey="U">Optimization and root finding (<code class="docutils literal"><span class="pre">scipy.optimize</span></code>)</a></li> 
    </ul>
              
              
    <ul class="nav nav-pills pull-right">
      <li class="active">
        <a href="../genindex.html" title="General Index"
           accesskey="I">index</a>
      </li>
      <li class="active">
        <a href="../py-modindex.html" title="Python Module Index"
           >modules</a>
      </li>
      <li class="active">
        <a href="scipy.optimize.fmin_cobyla.html" title="scipy.optimize.fmin_cobyla"
           accesskey="N">next</a>
      </li>
      <li class="active">
        <a href="scipy.optimize.fmin_l_bfgs_b.html" title="scipy.optimize.fmin_l_bfgs_b"
           accesskey="P">previous</a>
      </li>
    </ul>
              
	    </div>
	  </div>
	</div>
        

	<div class="row-fluid">
      <div class="spc-rightsidebar span3">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/scipyshiny_small.png" alt="Logo">
            </a></p>
  <h4>Previous topic</h4>
  <p class="topless"><a href="scipy.optimize.fmin_l_bfgs_b.html"
                        title="previous chapter">scipy.optimize.fmin_l_bfgs_b</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="scipy.optimize.fmin_cobyla.html"
                        title="next chapter">scipy.optimize.fmin_cobyla</a></p>


        </div>
      </div>
          <div class="span9">
            
        <div class="bodywrapper">
          <div class="body" id="spc-section-body">
            
  <div class="section" id="scipy-optimize-fmin-tnc">
<h1>scipy.optimize.fmin_tnc<a class="headerlink" href="#scipy-optimize-fmin-tnc" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="scipy.optimize.fmin_tnc">
<code class="descclassname">scipy.optimize.</code><code class="descname">fmin_tnc</code><span class="sig-paren">(</span><em>func</em>, <em>x0</em>, <em>fprime=None</em>, <em>args=()</em>, <em>approx_grad=0</em>, <em>bounds=None</em>, <em>epsilon=1e-08</em>, <em>scale=None</em>, <em>offset=None</em>, <em>messages=15</em>, <em>maxCGit=-1</em>, <em>maxfun=None</em>, <em>eta=-1</em>, <em>stepmx=0</em>, <em>accuracy=0</em>, <em>fmin=0</em>, <em>ftol=-1</em>, <em>xtol=-1</em>, <em>pgtol=-1</em>, <em>rescale=-1</em>, <em>disp=None</em>, <em>callback=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scipy/scipy/blob/4e64658/scipy/optimize/tnc.py#L86-L277"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#scipy.optimize.fmin_tnc" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize a function with variables subject to bounds, using
gradient information in a truncated Newton algorithm. This
method wraps a C implementation of the algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>func</strong> : callable <code class="docutils literal"><span class="pre">func(x,</span> <span class="pre">*args)</span></code></p>
<blockquote>
<div><p>Function to minimize.  Must do one of:</p>
<ol class="arabic simple">
<li>Return f and g, where f is the value of the function and g its
gradient (a list of floats).</li>
<li>Return the function value but supply gradient function
separately as <em class="xref py py-obj">fprime</em>.</li>
<li>Return the function value and set <code class="docutils literal"><span class="pre">approx_grad=True</span></code>.</li>
</ol>
<p>If the function returns None, the minimization
is aborted.</p>
</div></blockquote>
<p><strong>x0</strong> : array_like</p>
<blockquote>
<div><p>Initial estimate of minimum.</p>
</div></blockquote>
<p><strong>fprime</strong> : callable <code class="docutils literal"><span class="pre">fprime(x,</span> <span class="pre">*args)</span></code>, optional</p>
<blockquote>
<div><p>Gradient of <em class="xref py py-obj">func</em>. If None, then either <em class="xref py py-obj">func</em> must return the
function value and the gradient (<code class="docutils literal"><span class="pre">f,g</span> <span class="pre">=</span> <span class="pre">func(x,</span> <span class="pre">*args)</span></code>)
or <em class="xref py py-obj">approx_grad</em> must be True.</p>
</div></blockquote>
<p><strong>args</strong> : tuple, optional</p>
<blockquote>
<div><p>Arguments to pass to function.</p>
</div></blockquote>
<p><strong>approx_grad</strong> : bool, optional</p>
<blockquote>
<div><p>If true, approximate the gradient numerically.</p>
</div></blockquote>
<p><strong>bounds</strong> : list, optional</p>
<blockquote>
<div><p>(min, max) pairs for each element in x0, defining the
bounds on that parameter. Use None or +/-inf for one of
min or max when there is no bound in that direction.</p>
</div></blockquote>
<p><strong>epsilon</strong> : float, optional</p>
<blockquote>
<div><p>Used if approx_grad is True. The stepsize in a finite
difference approximation for fprime.</p>
</div></blockquote>
<p><strong>scale</strong> : array_like, optional</p>
<blockquote>
<div><p>Scaling factors to apply to each variable.  If None, the
factors are up-low for interval bounded variables and
1+|x| for the others.  Defaults to None.</p>
</div></blockquote>
<p><strong>offset</strong> : array_like, optional</p>
<blockquote>
<div><p>Value to subtract from each variable.  If None, the
offsets are (up+low)/2 for interval bounded variables
and x for the others.</p>
</div></blockquote>
<p><strong>messages</strong> : int, optional</p>
<blockquote>
<div><p>Bit mask used to select messages display during
minimization values defined in the MSGS dict.  Defaults to
MGS_ALL.</p>
</div></blockquote>
<p><strong>disp</strong> : int, optional</p>
<blockquote>
<div><p>Integer interface to messages.  0 = no message, 5 = all messages</p>
</div></blockquote>
<p><strong>maxCGit</strong> : int, optional</p>
<blockquote>
<div><p>Maximum number of hessian*vector evaluations per main
iteration.  If maxCGit == 0, the direction chosen is
-gradient if maxCGit &lt; 0, maxCGit is set to
max(1,min(50,n/2)).  Defaults to -1.</p>
</div></blockquote>
<p><strong>maxfun</strong> : int, optional</p>
<blockquote>
<div><p>Maximum number of function evaluation.  if None, maxfun is
set to max(100, 10*len(x0)).  Defaults to None.</p>
</div></blockquote>
<p><strong>eta</strong> : float, optional</p>
<blockquote>
<div><p>Severity of the line search. if &lt; 0 or &gt; 1, set to 0.25.
Defaults to -1.</p>
</div></blockquote>
<p><strong>stepmx</strong> : float, optional</p>
<blockquote>
<div><p>Maximum step for the line search.  May be increased during
call.  If too small, it will be set to 10.0.  Defaults to 0.</p>
</div></blockquote>
<p><strong>accuracy</strong> : float, optional</p>
<blockquote>
<div><p>Relative precision for finite difference calculations.  If
&lt;= machine_precision, set to sqrt(machine_precision).
Defaults to 0.</p>
</div></blockquote>
<p><strong>fmin</strong> : float, optional</p>
<blockquote>
<div><p>Minimum function value estimate.  Defaults to 0.</p>
</div></blockquote>
<p><strong>ftol</strong> : float, optional</p>
<blockquote>
<div><p>Precision goal for the value of f in the stoping criterion.
If ftol &lt; 0.0, ftol is set to 0.0 defaults to -1.</p>
</div></blockquote>
<p><strong>xtol</strong> : float, optional</p>
<blockquote>
<div><p>Precision goal for the value of x in the stopping
criterion (after applying x scaling factors).  If xtol &lt;
0.0, xtol is set to sqrt(machine_precision).  Defaults to
-1.</p>
</div></blockquote>
<p><strong>pgtol</strong> : float, optional</p>
<blockquote>
<div><p>Precision goal for the value of the projected gradient in
the stopping criterion (after applying x scaling factors).
If pgtol &lt; 0.0, pgtol is set to 1e-2 * sqrt(accuracy).
Setting it to 0.0 is not recommended.  Defaults to -1.</p>
</div></blockquote>
<p><strong>rescale</strong> : float, optional</p>
<blockquote>
<div><p>Scaling factor (in log10) used to trigger f value
rescaling.  If 0, rescale at each iteration.  If a large
value, never rescale.  If &lt; 0, rescale is set to 1.3.</p>
</div></blockquote>
<p><strong>callback</strong> : callable, optional</p>
<blockquote>
<div><p>Called after each iteration, as callback(xk), where xk is the
current parameter vector.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>x</strong> : ndarray</p>
<blockquote>
<div><p>The solution.</p>
</div></blockquote>
<p><strong>nfeval</strong> : int</p>
<blockquote>
<div><p>The number of function evaluations.</p>
</div></blockquote>
<p><strong>rc</strong> : int</p>
<blockquote class="last">
<div><p>Return code, see below</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="scipy.optimize.minimize.html#scipy.optimize.minimize" title="scipy.optimize.minimize"><code class="xref py py-obj docutils literal"><span class="pre">minimize</span></code></a></dt>
<dd>Interface to minimization algorithms for multivariate functions. See the ‘TNC’ <em class="xref py py-obj">method</em> in particular.</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The underlying algorithm is truncated Newton, also called
Newton Conjugate-Gradient. This method differs from
scipy.optimize.fmin_ncg in that</p>
<ol class="arabic simple">
<li>It wraps a C implementation of the algorithm</li>
<li>It allows each variable to be given an upper and lower bound.</li>
</ol>
<p>The algorithm incoporates the bound constraints by determining
the descent direction as in an unconstrained truncated Newton,
but never taking a step-size large enough to leave the space
of feasible x’s. The algorithm keeps track of a set of
currently active constraints, and ignores them when computing
the minimum allowable step size. (The x’s associated with the
active constraint are kept fixed.) If the maximum allowable
step size is zero then a new constraint is added. At the end
of each iteration one of the constraints may be deemed no
longer active and removed. A constraint is considered
no longer active is if it is currently active
but the gradient for that variable points inward from the
constraint. The specific constraint removed is the one
associated with the variable of largest index whose
constraint is no longer active.</p>
<p>Return codes are defined as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="n">Infeasible</span> <span class="p">(</span><span class="n">lower</span> <span class="n">bound</span> <span class="o">&gt;</span> <span class="n">upper</span> <span class="n">bound</span><span class="p">)</span>
 <span class="mi">0</span> <span class="p">:</span> <span class="n">Local</span> <span class="n">minimum</span> <span class="n">reached</span> <span class="p">(</span><span class="o">|</span><span class="n">pg</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">1</span> <span class="p">:</span> <span class="n">Converged</span> <span class="p">(</span><span class="o">|</span><span class="n">f_n</span><span class="o">-</span><span class="n">f_</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">2</span> <span class="p">:</span> <span class="n">Converged</span> <span class="p">(</span><span class="o">|</span><span class="n">x_n</span><span class="o">-</span><span class="n">x_</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">|</span> <span class="o">~=</span> <span class="mi">0</span><span class="p">)</span>
 <span class="mi">3</span> <span class="p">:</span> <span class="n">Max</span><span class="o">.</span> <span class="n">number</span> <span class="n">of</span> <span class="n">function</span> <span class="n">evaluations</span> <span class="n">reached</span>
 <span class="mi">4</span> <span class="p">:</span> <span class="n">Linear</span> <span class="n">search</span> <span class="n">failed</span>
 <span class="mi">5</span> <span class="p">:</span> <span class="n">All</span> <span class="n">lower</span> <span class="n">bounds</span> <span class="n">are</span> <span class="n">equal</span> <span class="n">to</span> <span class="n">the</span> <span class="n">upper</span> <span class="n">bounds</span>
 <span class="mi">6</span> <span class="p">:</span> <span class="n">Unable</span> <span class="n">to</span> <span class="n">progress</span>
 <span class="mi">7</span> <span class="p">:</span> <span class="n">User</span> <span class="n">requested</span> <span class="n">end</span> <span class="n">of</span> <span class="n">minimization</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Wright S., Nocedal J. (2006), ‘Numerical Optimization’</p>
<p>Nash S.G. (1984), “Newton-Type Minimization Via the Lanczos Method”,
SIAM Journal of Numerical Analysis 21, pp. 770-778</p>
</dd></dl>

</div>


          </div>
        </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container container-navbar-bottom">
      <div class="spc-navbar">
        
      </div>
    </div>
    <div class="container">
    <div class="footer">
    <div class="row-fluid">
    <ul class="inline pull-left">
      <li>
        &copy; Copyright 2008-2016, The Scipy community.
      </li>
      <li>
      Last updated on Sep 21, 2017.
      </li>
      <li>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.6.3.
      </li>
    </ul>
    </div>
    </div>
    </div>
  </body>
</html>